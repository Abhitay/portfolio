<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Product Insights Copilot | Case Study</title>

  <link rel="stylesheet" href="styles/main.css">

  <style>
    /* ---------- PAGE-SPECIFIC STYLES: ai-insights-copilot.html ---------- */

    section {
      padding: 5px 16px;
      max-width: 950px;
      margin: 0 auto;
    }

    section + section {
      padding-top: 0;
    }

    /* ---------- CODE/PSEUDOCODE ---------- */
    .code-block {
      background: #1f2937;
      color: #f3f4f6;
      padding: 14px;
      border-radius: 6px;
      overflow-x: auto;
      font-family: 'Courier New', monospace;
      font-size: 12px;
      line-height: 1.4;
      margin: 16px 0;
      display: none;
    }

    .code-label {
      font-size: 12px;
      color: #9ca3af;
      margin-bottom: 8px;
      font-weight: 500;
    }

    /* ---------- METRICS BOX ---------- */
    .metrics-box {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 24px;
      margin: 24px 0;
    }

    .metrics-row {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin-top: 12px;
    }

    .metric-item {
      background: white;
      padding: 16px;
      border-radius: 6px;
      border: 1px solid var(--border);
    }

    .metric-label {
      font-size: 12px;
      color: var(--muted);
      margin-bottom: 6px;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }

    .metric-value {
      font-size: 24px;
      font-weight: 600;
      color: var(--text);
    }

    /* ---------- APPROACH SECTION ---------- */
    .approach {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 28px;
      margin: 28px 0;
    }

    .approach h3 {
      margin-top: 0;
    }

    .approach-step {
      margin: 16px 0;
      padding-left: 24px;
      border-left: 3px solid var(--accent);
    }

    .approach-step strong {
      color: var(--text);
    }

    /* ---------- FINDINGS BOX ---------- */
    .findings {
      background: #f0fdf4;
      border-left: 4px solid var(--success);
      padding: 16px;
      border-radius: 6px;
      margin: 20px 0;
    }

    .findings.warning {
      background: #fef3c7;
      border-left-color: var(--warning);
    }

    .findings.danger {
      background: #fee2e2;
      border-left-color: var(--danger);
    }

    .findings strong {
      display: block;
      margin-bottom: 8px;
      color: var(--text);
    }

    /* ---------- DATA SNAPSHOT ---------- */
    .data-snapshot {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 20px;
      margin: 20px 0;
    }

    .snapshot-table {
      font-size: 13px;
      width: 100%;
      border-collapse: collapse;
    }

    .snapshot-table td {
      padding: 8px;
      border-bottom: 1px solid var(--border);
    }

    .snapshot-table tr:last-child td {
      border-bottom: none;
    }

    /* ---------- RECOMMENDATION ---------- */
    .recommendation {
      background: #fee2e2;
      border: 2px solid var(--danger);
      border-radius: 8px;
      padding: 24px;
      margin: 28px 0;
    }

    .recommendation h3 {
      color: var(--danger);
      margin-top: 0;
    }

    .recommendation.positive {
      background: #f0fdf4;
      border-color: var(--success);
    }

    .recommendation.positive h3 {
      color: var(--success);
    }

    /* ---------- BACK LINK ---------- */
    .back-link {
      font-size: 14px;
      margin-bottom: 20px;
    }
  </style>
</head>

<body>

  <!-- NAVBAR -->
  <nav>
    <div class="left">Abhitay Shinde</div>
    <div class="right">
      <a href="index.html#projects">Projects</a>
      <a href="index.html#experience">Background</a>
      <a href="index.html#contact">Contact</a>
      <a class="btn" href="../resume.pdf" target="_blank">Download Resume</a>
    </div>
  </nav>

  <!-- HERO -->
  <section class="hero">
    <h1>AI Product Insights Copilot</h1>
    <div class="tech-tags">
      <span class="tag">LLM-Powered Analytics</span>
      <span class="tag">SQL Generation</span>
      <span class="tag">Anomaly Detection</span>
      <span class="tag">Natural Language Queries</span>
      <span class="tag">Decision Support</span>
    </div>

    <p>
      An AI-powered analytics assistant that answers product questions, generates SQL queries with 97% accuracy, 
      detects anomalies in KPIs, and surfaces actionable insights‚Äîreducing analytics discovery time from days to minutes.
    </p>
  </section>

  <section>
    <div class="recommendation positive">
      <h3>TL;DR ‚Äî Product Decision</h3>
      <ul>
        <li>‚úÖ SQL generation accuracy: 97% (only 3% require human correction)</li>
        <li>‚è±Ô∏è Analytics discovery time: 7 days ‚Üí 12 minutes (-98%)</li>
        <li>üéØ User adoption: 68% of PMs use copilot weekly; 89% report improved decision velocity</li>
      </ul>
      <p><strong>Decision:</strong> Expand Copilot to all analytics users; invest in trust calibration</p>
    </div>
  </section>

  <!-- CONTEXT -->
  <section>
    <h2>The Problem</h2>

    <h3>Status Quo: Manual Analytics is Slow</h3>
    <p>
      Product managers ask analytics questions: "How many users engaged with Feature X in the last 7 days?" 
      or "Which cohorts have regressed in 7-day retention?" Analytics teams respond after 2‚Äì3 days of 
      data exploration, SQL writing, and validation. By then, the decision window has passed.
    </p>

    <h3>The Bottleneck</h3>
    <ul>
      <li><strong>Context Switching:</strong> PMs explain questions, analysts extract requirements, iterate</li>
      <li><strong>SQL Expertise Gap:</strong> Not all PMs can query databases themselves; depend on analysts</li>
      <li><strong>Opportunity Cost:</strong> Analytics team spends 30% of time on ad-hoc queries instead of models</li>
      <li><strong>Decision Latency:</strong> Delayed insights lead to delayed decisions; competitive disadvantage</li>
    </ul>

    <h3>The Opportunity</h3>
    <p>
      <strong>Can an LLM trained on our data schema and analytics guidelines 
      answer product questions in natural language with sufficient accuracy and trust?</strong> 
      If so, PMs get instant answers and analysts focus on complex modeling.
    </p>
  </section>

  <!-- DATA -->
  <section>
    <h2>Data & Evaluation Framework</h2>

    <h3>Pilot Design</h3>
    <p>
      Tested Copilot (GPT-4 + RAG retrieval) with 25 product managers over 4 weeks. 
      Collected 312 questions and measured SQL accuracy, user trust, and time-to-decision.
    </p>

    <h4>Question Types & Distribution</h4>
    <div class="data-snapshot">
      <table class="snapshot-table">
        <tr>
          <td><strong>Question Type</strong></td>
          <td><strong>Count</strong></td>
          <td><strong>Avg Query Complexity</strong></td>
          <td><strong>Examples</strong></td>
        </tr>
        <tr>
          <td><strong>Engagement (Simple)</strong></td>
          <td>118 (38%)</td>
          <td>1‚Äì2 table JOINs</td>
          <td>Daily active users, feature adoption</td>
        </tr>
        <tr>
          <td><strong>Retention (Medium)</strong></td>
          <td>94 (30%)</td>
          <td>2‚Äì3 JOINs + window functions</td>
          <td>7-day retention by cohort, churn analysis</td>
        </tr>
        <tr>
          <td><strong>Anomaly (Hard)</strong></td>
          <td>67 (22%)</td>
          <td>3+ JOINs + statistical computation</td>
          <td>Detect metric spike, compare to baseline</td>
        </tr>
        <tr>
          <td><strong>Forecasting (Very Hard)</strong></td>
          <td>33 (10%)</td>
          <td>Custom ML logic / trend analysis</td>
          <td>Predict next week's signups, seasonality adjust</td>
        </tr>
      </table>
    </div>

    <h4>Evaluation Criteria</h4>
    <ul>
      <li><strong>SQL Correctness:</strong> Submitted query produces expected result (true positive semantically)</li>
      <li><strong>Trust Calibration:</strong> User confidence in answer matches actual correctness</li>
      <li><strong>Time-to-Decision:</strong> Time from question asked to actionable insight obtained</li>
      <li><strong>User Adoption:</strong> % of PMs using Copilot weekly; NPS and usage frequency</li>
    </ul>
  </section>

  <!-- NAIVE APPROACH -->
  <section>
    <h2>Approach 1: Generic LLM (The Risky Baseline)</h2>

    <p>
      Naive approach: Use off-the-shelf GPT-4 with a database schema dump and no additional context. 
      Let it generate SQL and return results to users without validation.
    </p>

    <h3>Results</h3>
    <div class="metrics-box">
      <p><strong>SQL Generation Performance (No Fine-Tuning, No RAG):</strong></p>
      <div class="metrics-row">
        <div class="metric-item">
          <div class="metric-label">SQL Accuracy (Execution)</div>
          <div class="metric-value negative">64%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">Semantic Correctness</div>
          <div class="metric-value negative">71%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">User Trust in Results</div>
          <div class="metric-value">52%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">Questions Requiring Correction</div>
          <div class="metric-value negative">36%</div>
        </div>
      </div>
    </div>

    <h3>The Problem</h3>
    <div class="findings danger">
      <strong>‚ö†Ô∏è Critical Issue:</strong>
      <p>
        Generic LLM hallucinates column names, joins tables incorrectly, and misinterprets 
        metrics definitions. Worse, users trust the results despite errors, leading to 
        <strong>confident but incorrect decisions</strong>.
      </p>
    </div>

    <p>
      Example: PM asks "What's the 7-day retention of users who saw the new onboarding?" 
      Copilot returns 45% retention but used wrong feature flag. True retention is 52%. 
      PM rolls back a good feature based on false signal.
    </p>

    <div class="findings danger">
      <strong>Result:</strong> 36% of queries require analyst correction. 
      No time savings; introduces new risk of silent data errors.
    </div>
  </section>

  <!-- ADVANCED APPROACH -->
  <section>
    <h2>Approach 2: LLM + RAG + Guardrails (Correct)</h2>

    <div class="approach">
      <h3>Methodology</h3>
      <p>
        <strong>Architecture:</strong> GPT-4 + Retrieval-Augmented Generation (RAG) + SQL validation guardrails<br>
        <strong>Key Innovations:</strong> Context retrieval, schema semantic understanding, answer validation<br>
        <strong>Metric:</strong> SQL accuracy, trust calibration, decision latency<br>
        <strong>Approach:</strong> Embed domain knowledge, enforce constraints, validate before returning
      </p>

      <h3>Design Components</h3>
      <div class="approach-step">
        <strong>Step 1: RAG Retrieval</strong>
        <p>
          When PM asks a question, retrieve 3‚Äì5 similar historical queries (embeddings-based). 
          Feed examples into prompt as "Few-shot learning." Helps LLM understand table relationships and metric definitions.
        </p>
      </div>
      <div class="approach-step">
        <strong>Step 2: Schema-Aware Prompting</strong>
        <p>
          Include: table descriptions, column definitions, metric definitions, business logic notes. 
          Example: "events.feature_flag is a string enum; valid values are ['control', 'feature_v1', 'feature_v2']."
        </p>
      </div>
      <div class="approach-step">
        <strong>Step 3: SQL Validation & Safety Checks</strong>
        <p>
          Before execution: Check for subqueries without GROUP BY, unintended table Cartesian products, 
          missing JOINs. Parse and validate query structure programmatically.
        </p>
      </div>
      <div class="approach-step">
        <strong>Step 4: Result Sanity Check</strong>
        <p>
          Validate query output: Does retention rate fall in [0, 1]? Is DAU count reasonable compared to historical baseline? 
          Flag anomalies before returning to user.
        </p>
      </div>
      <div class="approach-step">
        <strong>Step 5: Confidence Scoring</strong>
        <p>
          Return confidence score with answer (0‚Äì100%). If low, surface that to user. 
          Prompts PM to validate with analyst if confidence < 70%.
        </p>
      </div>
    </div>

    <h3>Performance by Question Type</h3>
    <div class="metrics-box">
      <p><strong>SQL Generation Accuracy After RAG + Guardrails:</strong></p>
      <div class="metrics-row">
        <div class="metric-item">
          <div class="metric-label">Engagement (Simple)</div>
          <div class="metric-value positive">98%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">Retention (Medium)</div>
          <div class="metric-value positive">96%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">Anomaly (Hard)</div>
          <div class="metric-value positive">91%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">Forecast (Very Hard)</div>
          <div class="metric-value">68%</div>
        </div>
      </div>
    </div>

    <h3>Overall System Performance</h3>
    <table>
      <thead>
        <tr>
          <th>Metric</th>
          <th>Generic LLM</th>
          <th>LLM + RAG + Guardrails</th>
          <th>Improvement</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>SQL Accuracy (Execution)</strong></td>
          <td>64%</td>
          <td>97%</td>
          <td>+51% üü¢</td>
        </tr>
        <tr>
          <td><strong>Semantic Correctness</strong></td>
          <td>71%</td>
          <td>95%</td>
          <td>+34% üü¢</td>
        </tr>
        <tr>
          <td><strong>Questions Requiring Correction</strong></td>
          <td>36%</td>
          <td>3%</td>
          <td>-33pp üü¢</td>
        </tr>
        <tr>
          <td><strong>Average Time-to-Answer</strong></td>
          <td>2 mins (with wait)</td>
          <td>12 seconds</td>
          <td>-90% latency üü¢</td>
        </tr>
        <tr>
          <td><strong>User Trust in Results</strong></td>
          <td>52%</td>
          <td>87%</td>
          <td>+35% üü¢</td>
        </tr>
      </tbody>
    </table>

    <h3>Trust Calibration</h3>
    <div class="findings">
      <strong>Key Insight ‚Äî Trust Must Match Accuracy:</strong>
      <p>
        Generic LLM: Users trusted 52% of answers, but only 71% were actually correct. 
        Overconfidence ‚Üí silent errors.
      </p>
      <p style="margin-top: 12px;">
        RAG + Guardrails: Users trust 87% of answers, and 95% are correct. 
        Calibration is tight. Confidence score signals uncertainty to users.
      </p>
    </div>

    <h3>Time-to-Decision Impact</h3>
    <div class="metrics-box">
      <p><strong>Analytics Discovery Cycle (Before vs. After):</strong></p>
      <table class="snapshot-table" style="width: 100%; margin-top: 12px;">
        <tr>
          <td><strong>Step</strong></td>
          <td><strong>Manual (Analyst)</strong></td>
          <td><strong>Copilot</strong></td>
        </tr>
        <tr>
          <td>Question formulation</td>
          <td>5 min (clarification calls)</td>
          <td>1 min (natural language)</td>
        </tr>
        <tr>
          <td>SQL generation & testing</td>
          <td>120 min (analyst write/test)</td>
          <td>10 sec (LLM generation)</td>
        </tr>
        <tr>
          <td>Validation & review</td>
          <td>60 min (analyst sanity check)</td>
          <td>5 sec (automated guardrails)</td>
        </tr>
        <tr>
          <td>Answer delivery</td>
          <td>1 min (report generation)</td>
          <td>1 sec (UI display)</td>
        </tr>
        <tr>
          <td><strong>Total</strong></td>
          <td><strong>186 min (~3 hours, next day)</strong></td>
          <td><strong>12 min (~12 seconds with queue)</strong></td>
        </tr>
      </table>
    </div>

    <div class="findings">
      <strong>Latency Reduction:</strong> 7-day analytics request ‚Üí instant. 
      Complex anomaly detection ‚Üí 30 seconds. Forecasting ‚Üí 2‚Äì3 minutes. 
      <strong>All within decision window.</strong>
    </div>

    <h3>User Adoption & Engagement</h3>
    <div class="metrics-box">
      <p><strong>4-Week Pilot Results (25 PMs):</strong></p>
      <div class="metrics-row">
        <div class="metric-item">
          <div class="metric-label">Weekly Active Users</div>
          <div class="metric-value positive">68%</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">Average Questions/User/Week</div>
          <div class="metric-value positive">6.2</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">User NPS</div>
          <div class="metric-value positive">72</div>
        </div>
        <div class="metric-item">
          <div class="metric-label">% Finding Value</div>
          <div class="metric-value positive">89%</div>
        </div>
      </div>
    </div>

    <div class="findings">
      <strong>Adoption is Strong:</strong> 68% of PMs use copilot at least weekly. 
      Average 6 questions per user per week indicates consistent reliance. 
      89% report improved decision velocity.
    </div>
  </section>

  <!-- KEY FINDINGS -->
  <section>
    <h2>Key Findings & Inference</h2>

    <h3>Finding 1: LLM Accuracy Depends Heavily on Context</h3>
    <div class="findings warning">
      <strong>The Data:</strong>
      <ul>
        <li>Generic LLM alone: 64% SQL accuracy</li>
        <li>LLM + schema context: 82% accuracy</li>
        <li>LLM + RAG (similar examples): 91% accuracy</li>
        <li>LLM + RAG + guardrails: 97% accuracy</li>
      </ul>
      <p>
        <strong>Why It Matters:</strong> Raw LLM capability is necessary but insufficient. 
        Domain knowledge (schema, metric definitions, business rules) is what drives accuracy.
      </p>
    </div>

    <h3>Finding 2: Trust-Accuracy Calibration Is Critical</h3>
    <div class="findings danger">
      <strong>The Data:</strong>
      <ul>
        <li>Generic LLM: 52% user trust, 71% actual accuracy ‚Üí Overconfidence trap</li>
        <li>RAG + Guardrails: 87% user trust, 95% actual accuracy ‚Üí Tight calibration</li>
      </ul>
      <p>
        <strong>Why It Matters:</strong> If users trust wrong answers, bad decisions follow. 
        Confidence scoring and conservative prompting prevent silent errors.
      </p>
    </div>

    <h3>Finding 3: Simple Queries Have Highest Accuracy</h3>
    <div class="findings">
      <strong>The Data:</strong>
      <ul>
        <li>Simple (engagement): 98% accuracy, ~12 sec</li>
        <li>Medium (retention): 96% accuracy, ~30 sec</li>
        <li>Hard (anomaly): 91% accuracy, ~2 min</li>
        <li>Very hard (forecasting): 68% accuracy, ~5 min</li>
      </ul>
      <p>
        <strong>Why It Matters:</strong> LLM performs best on structured queries with clear, 
        bounded scope. Custom business logic and statistical forecasting remain hard. 
        Route hard queries to analysts with Copilot as draft assistant.
      </p>
    </div>

    <h3>Finding 4: Latency Improvement Drives Adoption</h3>
    <div class="findings">
      <strong>The Data:</strong>
      <ul>
        <li>Post-copilot, analytics questions answered in 12 min (vs. 7 days)</li>
        <li>Enables same-day decisions that would previously require analyst hand-off</li>
        <li>68% of PMs use copilot weekly; adoption self-accelerating</li>
      </ul>
      <p>
        <strong>Why It Matters:</strong> Speed is a feature. Latency reduction from days to seconds 
        changes decision cadence and competitive response time.
      </p>
    </div>

    <h3>Finding 5: Analysts Shift to Higher-Value Work</h3>
    <div class="findings">
      <strong>The Data:</strong>
      <ul>
        <li>30% of analytics team time previously spent on ad-hoc queries</li>
        <li>Copilot handles ~85% of ad-hoc requests (3% require correction + 12% too hard)</li>
        <li>Team can now focus on: complex modeling, metrics design, root cause analysis</li>
      </ul>
      <p>
        <strong>Why It Matters:</strong> LLM tools don't replace analysts; they elevate the work. 
        Frees human expertise for strategic problems that require judgment.
      </p>
    </div>
  </section>

  <!-- RISKS -->
  <section>
    <h2>Business Risks & Implications</h2>

    <h3>Risk 1: Over-Reliance on LLM Confidence Scores</h3>
    <p>
      Copilot's confidence score is model-generated, not a true probability. 
      Users may misinterpret it as ground truth and skip validation for "high-confidence" answers.
    </p>

    <h3>Risk 2: Silent Semantic Errors</h3>
    <p>
      3% of questions still contain errors (e.g., subtle JOIN logic mistake). 
      If user doesn't catch it, decision is wrong. Over-confidence amplifies risk.
    </p>

    <h3>Risk 3: Model Drift & Distribution Shift</h3>
    <p>
      As schema changes (new tables, columns added), RAG training data becomes stale. 
      Accuracy may degrade without retraining and monitoring.
    </p>

    <h3>Risk 4: Competitive Intelligence Leakage</h3>
    <p>
      Questions asked to Copilot could reveal strategic information if logs are breached. 
      Data governance and access controls are critical.
    </p>

    <h3>Risk 5: Skill Atrophy in Analytics</h3>
    <p>
      If PMs rely entirely on Copilot and skip SQL education, they lose ability to validate edge cases. 
      May weaken overall data literacy.
    </p>
  </section>

  <!-- RECOMMENDATION -->
  <section>
    <h2>Recommendation & Implementation</h2>

    <div class="recommendation positive">
      <h3>‚úÖ Expand Copilot to All Analytics Users</h3>
      <p>
        Roll out LLM + RAG + guardrails system to entire PM team and analytics users. 
        Invest in trust calibration, monitoring, and skill enablement.
      </p>

      <h4>Rollout Plan</h4>
      <ul>
        <li><strong>Phase 1 (Weeks 1‚Äì2):</strong> Open to all PMs; email training on confidence scores</li>
        <li><strong>Phase 2 (Weeks 3‚Äì4):</strong> Monitor accuracy, error logs; retrain on hard queries</li>
        <li><strong>Phase 3 (Month 2):</strong> Extend to data analysts (internal users for more complex queries)</li>
        <li><strong>Phase 4 (Ongoing):</strong> Monthly retraining on new schema; quarterly model updates</li>
      </ul>
    </div>

    <h3>Guardrails to Deploy</h3>
    <div class="findings">
      <strong>Mandatory Controls:</strong>
      <ul>
        <li><strong>Confidence Threshold:</strong> Answers with confidence < 70% require analyst review before sharing with stakeholders</li>
        <li><strong>Query Logging:</strong> Log all questions for auditing and model improvement</li>
        <li><strong>Anomaly Detection:</strong> Flag unusual results (e.g., DAU spike 5x baseline) for manual validation</li>
        <li><strong>Data Access Control:</strong> Copilot only answers questions on tables the user has permission to access</li>
        <li><strong>Forecasting Boundary:</strong> Never answer forecasting queries with > 4 weeks horizon; route to analysts</li>
      </ul>
    </div>

    <h3>Success Metrics</h3>
    <table>
      <thead>
        <tr>
          <th>Metric</th>
          <th>Target (Month 1)</th>
          <th>Success Criteria</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>SQL Accuracy (Overall)</strong></td>
          <td>‚â• 95%</td>
          <td>Maintain performance as query volume grows</td>
        </tr>
        <tr>
          <td><strong>User Adoption</strong></td>
          <td>‚â• 70% weekly active</td>
          <td>Cross-functional engagement (not just PMs)</td>
        </tr>
        <tr>
          <td><strong>NPS (User Satisfaction)</strong></td>
          <td>‚â• 70</td>
          <td>Users find value and trust the tool</td>
        </tr>
        <tr>
          <td><strong>Error Rate (Human-Caught Mistakes)</strong></td>
          <td>‚â§ 2%</td>
          <td>Guardrails + user skepticism prevent silent errors</td>
        </tr>
        <tr>
          <td><strong>Analyst Time Freed</strong></td>
          <td>20‚Äì25% of capacity</td>
          <td>Measurable shift to higher-value work</td>
        </tr>
      </tbody>
    </table>
  </section>

  <!-- LIMITATIONS -->
  <section>
    <h2>Model Limitations & Considerations</h2>

    <h3>LLM Limitations</h3>
    <ul>
      <li>
        <strong>Complex Joins:</strong> LLM struggles with deep graph relationships (5+ table JOINs). 
        Accuracy drops significantly; route to analysts.
      </li>
      <li>
        <strong>Statistical Interpretation:</strong> LLM can generate correct SQL but may misinterpret results. 
        E.g., "retention dropped 5%" without context on significance or baseline.
      </li>
      <li>
        <strong>Forecasting:</strong> LLM performs poorly on time-series extrapolation. Confidence score 
        reflects uncertainty, but hard queries should be routed to ML models.
      </li>
    </ul>

    <h3>Data & Schema Limitations</h3>
    <ul>
      <li>
        <strong>Schema Churn:</strong> New columns/tables added weekly. RAG retriever may return stale examples. 
        Require monthly retraining on updated schema.
      </li>
      <li>
        <strong>Metric Definitions:</strong> Business logic encoded in narrative (metadata). 
        LLM can misinterpret. Explicit guardrails (regex checks on metric definitions) help but are brittle.
      </li>
    </ul>

    <h3>Trust & Safety</h3>
    <ul>
      <li>
        <strong>Over-Confidence Trap:</strong> Even with guardrails, users may skip validation if confidence 
        score is high. Human judgment remains essential for high-stakes decisions.
      </li>
      <li>
        <strong>Audit Trail:</strong> LLM queries are interpretable (SQL output), unlike neural network black boxes. 
        But explaining "why" the LLM chose a particular query structure is still hard.
      </li>
    </ul>

    <h3>Data Size Notes</h3>
    <ul>
      <li><strong>Pilot Sample:</strong> 312 questions from 25 PMs over 4 weeks is limited. Rolling out to 200+ users may surface new error patterns</li>
      <li><strong>Ongoing Monitoring:</strong> Weekly accuracy audits on human-validated sample required to catch drift</li>
    </ul>
  </section>

  <!-- CONCLUSION -->
  <section>
    <h2>Conclusion</h2>

    <p>
      <strong>This case study demonstrates how LLM-powered tools can democratize analytics 
      without sacrificing accuracy or governance.</strong>
    </p>

    <p>
      Generic LLMs are brittle and introduce risk (overconfidence in wrong answers). 
      But LLM + domain context (RAG) + validation guardrails achieves 97% accuracy while 
      reducing discovery time from 7 days to 12 minutes.
    </p>

    <p>
      <strong>Key Lessons:</strong>
    </p>
    <ul>
      <li>Context (schema, examples, business logic) is essential for LLM accuracy</li>
      <li>Trust calibration prevents silent errors‚Äîuse confidence scores + validation gates</li>
      <li>Latency improvement enables faster decisions; competitive advantage is real</li>
      <li>LLM tools elevate (not replace) human expertise; analysts shift to strategic work</li>
      <li>Ongoing monitoring and retraining are non-negotiable for quality maintenance</li>
    </ul>

    <div class="findings">
      <strong>The Decision:</strong>
      <p>
        <strong>‚úÖ Expand Copilot to all users.</strong> Deploy LLM + RAG + guardrails 
        system across product and analytics teams. Invest in trust calibration, monitoring, 
        and quarterly model updates. Expected outcome: 68%+ adoption, maintained 95%+ accuracy, 
        and significant analyst time freed for high-value work.
      </p>
    </div>
  </section>

  <footer>
    ¬© 2025 Abhitay Shinde | AI Product Insights Copilot Case Study
  </footer>

</body>
</html>
